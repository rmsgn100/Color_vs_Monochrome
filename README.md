# Color Camera vs Monochrome Camera
파일 구성
> 데이터 셋 : Train, Test, Test.csv
> 
> 저장한 모델 : final_model
> 
> 가상환경에서 재구현한 파일 : Copy_Project1.ipynb
> 
> 코랩에서 프로젝트를 진행한 파일 : Project1.ipynb
> 
> Dependency : requirements.txt

<p align="center">
<img width="700" alt="스크린샷 2021-02-21 오후 9 33 54" src="https://user-images.githubusercontent.com/61172021/119165497-7f643100-ba98-11eb-9914-e0a857af3587.png">
</p>

## 프로젝트 개요 

* 자율주행의 핵심 기술중 하나인 표지판 인식 기능의 성능이 흑백이미지와 컬러이미지에서 차이를 보이는지 분석.

* 자율 주행시스템의 판단은 사람의 목숨과 직결되기 때문에 빠를수록, 정확할수록 좋다. 그리고, 제조과정에서의 원가절감은 언제나 환영이다. 이 프로젝트는 컬러/흑백 이미지를 사용할 때의 모델의 정확도, 학습/예측 속도를 비교/분석한 결과와 컬러/흑백 카메라의 가격, 해상도를 조사한 결과를 바탕으로 흑백 카메라를 사용하는 것이 좋다는 것을 주장하기 위한 것이다.

## 프로젝트 배경 지식

1. 자율주행 자동차에는 여러대의 카메라가 필수적으로 설치된다(ex. Waymo: 29개, Tesla: 9개). 그리고, 흑백 카메라는 컬러 카메라보다 저렴하다(약 10%). 즉, 흑백 이미지를 사용했을 때와 컬러 이미지를 사용했을 때의 표지판 인식 정확도에 차이가 없다면 흑백 카메라를 설치하는 것이 원가절감에 도움이 될 것이다.

<img align="right" width="450" alt="스크린샷 2021-02-21 오후 6 19 01" src="https://user-images.githubusercontent.com/61172021/119166028-1d57fb80-ba99-11eb-998d-e9049e8d2bb3.png">

2. 같은 화소수를 가진 컬러/흑백 카메라를 사용할 경우, 컬러 카메라로 촬영한 이미지의 해상도가 흑백 이미지의 ⅓ 이기때문에, 흑백 카메라를 사용하는 것이 유리하다. (컬러 카메라는 흑백 카메라의 센서 위에 Bayer 필터(RGB 필터)를 부착한 것이기 때문에, 색깔별로 화소수를 나눠가진다. 즉, 컬러 카메라는 Bayer 필터를 추가적으로 부착해야하기 때문에 더 비싸고 이미지의 해상도는 낮음)

3. 컬러 이미지는 채널이 3개로(RGB) 흑백 이미지보다 데이터 사이즈가 3배 크기 때문에 더 큰 저장 공간을 필요로 한다. 또한, 큰 데이터 사이즈 때문에 컬러 이미지를 처리하는 속도가 흑백 이미지를 처리하는 속도보다 느리기 때문에 자율주행 판단을 지연시킬 수 있다.

4. 컴퓨터를 사용한 이미지 처리에서는 흑백 이미지가 컬러 이미지보다 더 선호된다. 색깔은 인간에겐 많은 정보를 주지만, 컴퓨터는 흑백 정보만으로도 이미지의 패턴, 윤곽, 모양 등의 속성을 충분히 파악할 수 있다고 한다.

## 가설

딥러닝 모델은 컬러 이미지를 사용했을 때의 학습/예측 시간이 흑백 이미지를 사용할 때보다 오래걸리고, 정확도에선 큰 차이를 보이지 않을 것이다.

## 진행 순서

1. 이미지 인식을 위한 모델들(머신러닝 : Random forest, 딥러닝 : CNN)을 만들고, 컬러 이미지를 가지고 모델의 성능(정확도, 학습/예측 시간)을 측정한다.

(머신러닝과 딥러닝 모델을 둘 다 사용해본 이유는 단순히 딥러닝 모델(CNN기반의 모델)이 이미지 분석에 더 효율적이라는 것을 보기 위함이다. 자세히 봐야할 것은 컬러 이미지와 흑백 이미지의 결과 비교이다.)

2. 흑백 이미지를 가지고 같은 학습/테스트를 진행한다.

3. 가설 검증 : 1번과 2번의 결과를 비교한다. 이때, 학습/예측 속도와 정확도를 모두 비교한다.

4. 더 좋은 정확도와 처리속도를 보이는 모델을 만들기 위해 CNN 모델을 개선시키는 방법들 (EfficientNet 논문에 소개된 Width Scaling, Depth Scaling, Resolution Scaling, Compound Scaling)을 적용해 본다.

5. Augmentation 을 통해 훈련 데이터셋을 늘려 학습을 진행한다.

6. CV(Cross Validation) 를 사용해서 데이터 편중과 과적합을 막고 일반화된 모델 얻는다.

## 데이터 

도로 표지판 이미지와 레이블은 43종류가 있다. 

<p align="center">
<img width="700" alt="스크린샷 2021-02-21 오후 9 33 54" src="https://user-images.githubusercontent.com/61172021/119166833-12519b00-ba9a-11eb-9cfd-ef942383e9e5.png">
</p>

Train 데이터 폴더

* Train 폴더 내에 43개의 하위 폴더(0~42)가 있고, 각 하위 폴더의 이름(번호)은 표지판의 종류(클래스)를 의미한다.
* 각각의 폴더(클래스)에 들어있는 이미지의 개수와 그 크기는 다르다.
* Train 폴더에 들어있는 이미지의 총 갯수는 약 39000개이다.

Test 데이터 폴더

* Test 폴더는 Train 폴더와 다르게 하위폴더가 존재하지않고, 약 12600개의 이미지들이 무작위로 존재한다. 
* 각 이미지들에 대한 label 은 Test.csv 파일에있다.

Test.csv 파일

* Test 데이터 셋에 있는 이미지들의 정보(Path, ClassId, Width, Height 등)를 제공한다.
 
## 머신러닝(Random Forest) 결과 비교

<img width="1004" alt="스크린샷 2021-05-22 오전 2 59 01" src="https://user-images.githubusercontent.com/61172021/119179250-ac6d0f80-baa9-11eb-989f-04fcfdbe61ae.png">

1. 머신러닝을 사용할 때의 정확도는 80%를 넘기기가 힘들다. 그 이유는 이미지 데이터를 1차원적으로만 보기 때문이다.
2. 흑백 이미지를 사용할 때의 학습 속도와 예측 속도가 훨씬 빠르고, 정확도엔 큰 차이가 없다.

## 딥러닝(CNN) 결과 비교

<img width="1004" alt="스크린샷 2021-05-22 오전 3 04 51" src="https://user-images.githubusercontent.com/61172021/119179913-7d0ad280-baaa-11eb-96f8-69ffc840c06c.png">

1. CNN 모델은 슬라이딩 윈도우 방식을 통해 이미지의 위치적인 특징을 추출할 수 있으므로, 머신러닝의 결과보다 훨씬 좋은 정확도를 보인다. 
2. 머신러닝의 결과와 동일하게, 흑백 이미지를 사용할 때의 학습 속도와 예측 속도가 훨씬 빠르고, 정확도는 비슷한 수치를 보여준다. 하지만 이게 전부가 아니다.
3. 위 "프로젝트 배경 지식"에서 설명한 대로, 실제로 흑백 카메라를 사용한다면 그 이미지의 해상도는 컬러 이미지의 해상도의 3배이다. 이 해상도 차이를 실제로 적용했을 때의 CNN모델의 정확도 차이는 84.5%(컬러) vs 95.21%(흑백) 으로, 흑백 카메라를 사용한 정확도가 현실에선 훨씬 좋다.


## Grad_CAM

Grad_CAM 은 CNN 모델이 의사결정을 할 때 이미지의 어떤 특징들을 보고 그런 결정을 내렸는지를 보여주는 도구이다. 여기선, 컬러 이미지를 통해 학습한 모델과 흑백 이미지를 통해 학습한 모델이 각 이미지(컬러, 흑백)의 특징을 비슷하게 파악하고 있는지, 아니면 각자 전혀 다르게 이미지를 파악 하는지를 확인해 볼 수 있다.

<p align="center">
<img width="500" alt="스크린샷 2021-02-21 오후 9 33 54" src="https://user-images.githubusercontent.com/61172021/120095302-2fecc780-c160-11eb-8ec8-8014c88057cc.png">
</p>

두 모델은 이미지의 특징들을 비슷하게 파악하는 것으로 보인다. 왼쪽이 컬러 이미지를 통해 학습한 모델이고, 오른쪽이 흑백 이미지를 통해 학습한 모델이다. 두 모델 모두 표지판의 모양과 표지판에 쓰여진 글자 정보를 잘 구별하고있다. 이것으로 보아, 컴퓨터는 이미지의 윤곽, 패턴, 모양 등의 특징들만으로도 물체를 식별할 수 있는 것으로 보인다.

## Scaling

<p align="center">
<img width="1000" alt="스크린샷 2021-02-21 오후 9 33 54" src="https://user-images.githubusercontent.com/61172021/120095604-c53c8b80-c161-11eb-958b-ff7d2a2e6c67.png">
</p>

2020년 9월에 발표된 논문 "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks" 에서는 CNN 모델의 성능을 올리는 방법으로 4가지 Scaling 방법을 소개했다. 그 중 첫번째인 Resolution Scaling 이란 심플하게 input 이미지의 해상도를 높이는 방법이다. 그리고 Width Scaling 은 위 그림과 같이 기본 모델의 filter 개수를 늘리는 방법으로, MobileNet, ShuffleNet 등이 Width Scaling 방법을 적용한 모델이다. 세번째 방법인 Depth Scaling 은 layer 의 개수를 늘리는 방법으로, 대표적으로 ResNet 이 Depth Scaling 방법을 적용한 모델이다. 마지막으로, Compound Scaling 이란 앞서 설명한 3가지 방법을 한번에 모두 사용하는 방법이다.

각각의 Scaling 방법을 적용했을 때의 결과를 비교해 보았다 : 

* Resolution Scaling : 95.21 %
* Width Scaling : 96.14 %
* Depth Scaling : 96.86 %
* Compound Scaling : 97.53 %

## Data Augmentation 

이미지 rotation/shift 와 같은 랜덤한 변화를 주어 훈련세트의 다양성을 증가시켜 모델의 성능을 개선시키는 방법

<p align="center">
<img width="918" alt="스크린샷 2021-05-30 오후 4 16 31" src="https://user-images.githubusercontent.com/61172021/120095712-688da080-c162-11eb-9fce-39651e782bcb.png">
</p>

처음 Data Augmentation 을 적용할 때 오히려 성능이 내려가는 상황을 겪었다. 왜 그런지 곰곰히 생각해보니 상하 반전, 좌우 반전같은 변화를 사용해서 그랬던 것 같다. 실제 표지판은 거꾸로 되어있을리가 없으니, 상하/좌우 반전같은 변화를 주어 학습하면 성능이 내려가는 결과를 낳게된다. 그리고, rotation_range(회전) 도 조금만(10도 정도만) 사용해야 한다. (90도로 꺾여있는 표지판은 없으니!)

* Data Augmentation 이전 : 97.53 %
* Data Augmentation 이후 : 98.62 %

## Cross Validation 

* 모든 데이터셋을 훈련에 사용할 수 있다는 장점이 있다.
* 훈련, 평가 시 사용되는 데이터의 편중과 과적합을 막을 수 있고, 조금 더 일반화된 모델을 만들 수 있다. 

<p align="center">
<img width="565" alt="스크린샷 2021-05-30 오후 4 22 31" src="https://user-images.githubusercontent.com/61172021/120095858-3fb9db00-c163-11eb-9c75-1cc0e132fa69.png">
</p>

* Cross Validation 이전 : 98.62 %
* Cross Validation 이후 : 98.75 %

## 결과 해석

* 컬러 이미지를 사용할 때와 흑백 이미지를 사용할 때의 모델의 정확도는 머신러닝과 딥러닝 모두에서 거의 비슷하다.
* 흑백 이미지를 사용할 때의 모델 학습/예측 속도가 훨씬 더 빠르다.
* 현실에서 흑백 카메라를 사용한다면 그 해상도가 컬러 카메라의 3배이므로 그에따라 모델의 정확도가 크게 좋아진다.
* 즉, 흑백 카메라를 사용하는 것이 가격, 속도, 정확도 모든 측면에서 좋다. 
* 사람에겐 표지판의 색깔 정보가 중요하겠지만, 컴퓨터는 패턴/윤곽/모양 등의 속성만으로도 표지판 구별이 가능하다고 볼 수 있다.
* 하드웨어(카메라) 교체를 통해 모델의 성능을 크게 개선시켰고, 추가적인 모델 성능 개선을 위해서 소프트웨어 측면의 노력(Scaling 기법들, Data Augmentation, Cross Validation)도 함께하여 최종적으로 98.75 % 라는 성능에 도달했다.
